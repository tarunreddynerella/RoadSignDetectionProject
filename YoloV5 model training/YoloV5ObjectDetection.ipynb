{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1682437622768,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"ALnvWznb-Uxx"},"outputs":[],"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    import zipfile\n","    with zipfile.ZipFile('/content/drive/MyDrive/DL Project/YoloV5DataSet.zip', 'r') as zip_ref:\n","        zip_ref.extractall('./')\n","except:\n","    print(\"Using Local Machine\")"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1682437622768,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"MwugvauE-Uxz"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 15627, done.\u001b[K\n","remote: Counting objects: 100% (234/234), done.\u001b[K\n","remote: Compressing objects: 100% (168/168), done.\u001b[K\n","remote: Total 15627 (delta 116), reused 138 (delta 66), pack-reused 15393\u001b[K\n","Receiving objects: 100% (15627/15627), 14.65 MiB | 10.19 MiB/s, done.\n","Resolving deltas: 100% (10644/10644), done.\n","zsh:1: command not found: pip\n"]}],"source":["import sys\n","!git clone https://github.com/ultralytics/yolov5.git\n","# sys.path.append('/path/to/yolov5')\n","!pip install -r yolov5/requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3451,"status":"ok","timestamp":1682437626217,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"UD-pI5fE-Uxz"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from yolov5.models.yolo import Model\n","from yolov5.utils.dataloaders import LoadImagesAndLabels\n","from yolov5.utils.general import check_requirements, set_logging\n","from yolov5.utils.loss import ComputeLoss\n","from yolov5.utils.plots import plot_labels, plot_results\n","from pathlib import Path\n","import yaml\n","\n","import os\n","import random\n","from pathlib import Path\n","import pandas as pd\n","import cv2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682437626218,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"rcIp8aLs-Ux0","outputId":"5259b2d4-9997-4bd8-8cd6-edbad218f2db"},"outputs":[],"source":["batchSize = 32\n","inputShape = (640, 640)\n","epochs = 100\n","numAnchors = 3\n","yolo5Version = 'm'\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"Using {} device\".format(device))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1682437626218,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"-bgVKnL3-Ux0"},"outputs":[],"source":["# Load custom dataset configuration\n","with open('signboard.yaml') as f:\n","    data = yaml.safe_load(f)\n","train_path, val_path = data['train'], data['val']\n","nc, names = data['nc'], data['names']"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1682437626218,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"ml1JDNXU-Ux1"},"outputs":[],"source":["# Create output directory\n","save_dir = Path('runs/train/signboard_exp')\n","(save_dir / 'weights').mkdir(parents=True, exist_ok=True)\n","set_logging(str(save_dir / 'train.log'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1682437626218,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"V1YSrL7YpJFa"},"outputs":[],"source":["def custom_collate_fn(batch):\n","    # Get the maximum length of tensors in the batch\n","    max_len = max([t.shape[0] for _, t, _, _ in batch])\n","\n","    # Pad the tensors to the same size and stack them together\n","    imgs = torch.stack([img for img, _, _, _ in batch])\n","    targets = [torch.cat([t, torch.zeros(max_len - t.shape[0], t.shape[1])], dim=0) for _, t, _, _ in batch]\n","    targets = torch.stack(targets)\n","    paths = [path for _, _, path, _ in batch]\n","    extra = [e for _, _, _, e in batch]\n","\n","    return imgs, targets, paths, extra"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":514,"status":"ok","timestamp":1682437626729,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"ePRSLUmi-Ux1","outputId":"3c871b6a-72a1-4934-a8e3-a623c8e5e802"},"outputs":[],"source":["# Load dataset\n","train_dataset = LoadImagesAndLabels(train_path, 640, 16, rect=True, pad=0.5)\n","val_dataset = LoadImagesAndLabels(val_path, 640, 16, rect=True, pad=0.5)\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, collate_fn=custom_collate_fn,shuffle=True, num_workers=4, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=16, collate_fn=custom_collate_fn,shuffle=False, num_workers=4, pin_memory=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":456,"status":"ok","timestamp":1682437627182,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"9RId9PAo-Ux1","outputId":"456741a5-793c-4795-e6ee-0a1c4b192601"},"outputs":[],"source":["print(\"Downloading Weights of yolo5 Verion \", yolo5Version)\n","weightsURL = \"https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5{}.pt\".format(yolo5Version)\n","!wget {weightsURL}"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682437627182,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"cQlM4j-R-Ux1"},"outputs":[],"source":["def CreateYolov5Model(numClasses: int, version: str):\n","    congfigFile = \"yolov5/models/yolov5{}.yaml\".format(version)\n","    model = Model(congfigFile, ch=3, nc=numClasses)\n","    ckpt = torch.load(f'yolov5{version}.pt', map_location=device)\n","    ckpt_model_dict = ckpt['model'].state_dict()\n","    compatible_weights = {k: v for k, v in ckpt_model_dict.items() if k in model.state_dict() and model.state_dict()[k].shape == v.shape}\n","    model.load_state_dict(compatible_weights, strict=False)\n","    model.hyp = ckpt['model'].hyp\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def TargetstoTensors(targets, batchSize, numAnchors, gridSizes):\n","    targetObj = []\n","    targetBox = []\n","    for grid_size in gridSizes:\n","        targetObj.append(torch.zeros((batchSize, numAnchors, grid_size, grid_size, 1)))\n","        targetBox.append(torch.zeros((batchSize, numAnchors, grid_size, grid_size, 4)))\n","\n","    for batch_index, target in enumerate(targets):\n","        x1, y1, x2, y2 = target.long()\n","        x_center, y_center, width, height = (x1 + x2) / 2, (y1 + y2) / 2, x2 - x1, y2 - y1\n","\n","        for i, grid_size in enumerate(gridSizes):\n","            x_cell, y_cell = int(x_center * grid_size), int(y_center * grid_size)\n","            anchor = 0\n","            try:\n","                targetObj[i][batch_index, anchor, y_cell, x_cell, 0] = 1\n","                targetBox[i][batch_index, anchor, y_cell, x_cell] = torch.tensor([x_center, y_center, width, height])\n","            except Exception as e:\n","                pass\n","    return targetObj, targetBox"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","class SignboardLoss(nn.Module):\n","    def __init__(self, num_anchors=3):\n","        super(SignboardLoss, self).__init__()\n","        self.num_anchors = num_anchors\n","\n","    def forward(self, preds, targets):\n","        objectLoss = torch.tensor(0.0, device=preds[0].device)\n","        boxLoss = torch.tensor(0.0, device=preds[0].device)\n","        batchSize = preds[0].size(0)\n","        gridSizes = [pred.size(2) for pred in preds]\n","        targetObjList, targetBoxList = TargetstoTensors(targets, batchSize, self.num_anchors, gridSizes)\n","\n","        for i, pred in enumerate(preds):\n","            targetObj = targetObjList[i].to(pred.device)\n","            targetBox = targetBoxList[i].to(pred.device)\n","\n","            objectLoss += nn.BCEWithLogitsLoss()(pred[..., 4:5], targetObj)\n","            boxLoss += nn.MSELoss()(pred[..., :4], targetBox)\n","\n","        total_loss = objectLoss + boxLoss\n","        return total_loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load model\n","numClasses = 47\n","model = CreateYolov5Model(numClasses,yolo5Version)\n","model = model.to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.937, weight_decay=0.0005, nesterov=True)\n","criterion = SignboardLoss()\n","criterion = criterion.to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":536},"executionInfo":{"elapsed":2622,"status":"error","timestamp":1682437634421,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"dvUPtqV8-Ux2","outputId":"62d7a7b7-eb82-4098-8bef-865a7dea7b97"},"outputs":[],"source":["\n","epochs = 100\n","best_fitness = float('inf')\n","\n","for epoch in range(epochs):\n","    model.train()\n","\n","    for i, (imgs, targets, paths, _) in enumerate(train_loader):\n","        imgs = imgs.to(device).float() / 255.0\n","        targets = targets.to(device)\n","\n","        # Forward pass\n","        pred = model(imgs)\n","        print(\"Pred shapes:\")\n","        for p in pred:\n","            print(p.shape)\n","        print(\"Targets shape:\", targets.shape)\n","        # Compute loss\n","        loss, loss_items = criterion(pred, targets)\n","        loss_items = torch.cat(loss_items)\n","\n","        # Backward pass\n","        loss.backward()\n","\n","        # Update weights\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","    # Validation\n","    model.eval()\n","    with torch.no_grad():\n","        for i, (imgs, targets, paths, _) in enumerate(val_loader):\n","            imgs = imgs.to(device).float() / 255.0\n","            targets = targets.to(device)\n","\n","            # Forward pass\n","            pred = model(imgs)\n","            print(\"Pred shape:\", pred.shape)\n","            print(\"Targets shape:\", targets.shape)\n","            # Compute loss\n","            val_loss, val_loss_items = criterion(pred, targets)\n","            val_loss_items = torch.cat(val_loss_items)\n","\n","    # Save best model\n","    if val_loss < best_fitness:\n","        best_fitness = val_loss\n","        torch.save(model.state_dict(), save_dir / 'weights' / 'best.pt')\n","\n","# Plot training results\n","plot_results(save_dir=save_dir)\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
