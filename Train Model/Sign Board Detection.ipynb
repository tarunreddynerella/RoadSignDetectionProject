{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Gi1JVb63nB1",
        "outputId": "4556ee59-cb00-491f-95c4-acb9962b7499"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "!pip install -r yolov5/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQdle6ECbu-5"
      },
      "outputs": [],
      "source": [
        "# Include all packages\n",
        "import gc\n",
        "import cv2\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from yolov5.models.yolo import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "\n",
        "import torchvision\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggf594ltbu-6"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/DL Project/DataSet.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('./')\n",
        "except:\n",
        "    print(\"Using Local Machine\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xd2tU8GB3nB3"
      },
      "outputs": [],
      "source": [
        "def ResizeImage(image: np.ndarray, x1: int, y1: int, x2: int, y2: int, newWidth: int, newHeight: int) -> tuple:\n",
        "    originalHeight, originalWidth = image.shape[:2]\n",
        "    widthScale = newWidth / originalWidth\n",
        "    heightScale = newHeight / originalHeight\n",
        "    resizedImage = cv2.resize(\n",
        "        image, (newWidth, newHeight), interpolation=cv2.INTER_LINEAR)\n",
        "    x1New, y1New = int(x1 * widthScale), int(y1 * heightScale)\n",
        "    x2New, y2New = int(x2 * widthScale), int(y2 * heightScale)\n",
        "    # scale = min(newWidth / originalWidth, newHeight / originalHeight)\n",
        "    # resizedImage = cv2.resize(image, (round(originalWidth * scale), round(originalHeight * scale)), interpolation=cv2.INTER_LINEAR)\n",
        "    # dx = round((newWidth - resizedImage.shape[1]) / 2)\n",
        "    # dy = round((newHeight - resizedImage.shape[0]) / 2)\n",
        "    # paddedImage = cv2.copyMakeBorder(resizedImage, dy, dy, dx, dx, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
        "    # x1New, y1New = int(x1 * scale + dx), int(y1 * scale + dy)\n",
        "    # x2New, y2New = int(x2 * scale + dx), int(y2 * scale + dy)\n",
        "    # return paddedImage, x1New, y1New, x2New, y2New\n",
        "    return resizedImage, x1New, y1New, x2New, y2New\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iMxCddibu-7"
      },
      "outputs": [],
      "source": [
        "def LoadDataSet(dataSetFolderPath: str) -> tuple:\n",
        "    images = []\n",
        "    annotations = []\n",
        "    annotationsFilePath = dataSetFolderPath+\"/allAnnotations.csv\"\n",
        "    annotationsDataFrame = pd.read_csv(annotationsFilePath, sep=\";\")\n",
        "    uniqueSigns = annotationsDataFrame['Annotation tag'].unique().tolist()\n",
        "    for index, row in annotationsDataFrame[1:].iterrows():\n",
        "        image = cv2.imread(dataSetFolderPath+\"/\"+row[0])\n",
        "        images.append(image)\n",
        "        annotations.append(\n",
        "            [row[2], row[3], row[4], row[5]])\n",
        "\n",
        "    del annotationsDataFrame\n",
        "\n",
        "    return images, annotations, len(uniqueSigns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87wkTQy53nB4"
      },
      "outputs": [],
      "source": [
        "def PreProcessDataSet(images: list, annotations: list, batchSize: int, resize: tuple) -> tuple:\n",
        "    resizedImages = []\n",
        "    newAnnotations = []\n",
        "    for i, image in enumerate(images):\n",
        "        [x1, y1, x2, y2] = annotations[i]\n",
        "        resizedImage, x1New, y1New, x2New, y2New = ResizeImage(\n",
        "            image, x1, y1, x2, y2, resize[0], resize[1])\n",
        "        resizedImages.append(resizedImage)\n",
        "        newAnnotations.append(\n",
        "            [x1New, y1New, x2New, y2New])\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        resizedImages, newAnnotations, test_size=0.3, random_state=42)\n",
        "\n",
        "    return X_train, X_val, y_train, y_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68sCzcEAbu-7"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inputData, label = self.data[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            inputData = self.transform(inputData)\n",
        "        inputData = torch.from_numpy(inputData).float()\n",
        "        label = torch.tensor(label).float()\n",
        "        return inputData, label\n",
        "\n",
        "def CreateDataLoaders(X_train, X_val, y_train, y_val, batchSize):\n",
        "    trainDataSet = []\n",
        "    valDataSet = []\n",
        "    for i in range(len(X_train)):\n",
        "        trainDataSet.append((X_train[i], y_train[i]))\n",
        "\n",
        "    for i in range(len(X_val)):\n",
        "        valDataSet.append((X_val[i], y_val[i]))\n",
        "\n",
        "    trainDataSet = CustomDataset(trainDataSet)\n",
        "    valDataSet = CustomDataset(valDataSet)\n",
        "    trainDataLoader = DataLoader(\n",
        "        trainDataSet, batch_size=batchSize, shuffle=True, num_workers=4)\n",
        "    valDataLoader = DataLoader(\n",
        "        valDataSet, batch_size=batchSize, shuffle=False, num_workers=4)\n",
        "\n",
        "    return trainDataLoader, valDataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owhzzQF61a0L"
      },
      "outputs": [],
      "source": [
        "\n",
        "def TargetstoTensors(targets, batchSize, numAnchors, gridSizes):\n",
        "    targetObj = []\n",
        "    targetBox = []\n",
        "    for grid_size in gridSizes:\n",
        "        targetObj.append(torch.zeros((batchSize, numAnchors, grid_size, grid_size, 1)))\n",
        "        targetBox.append(torch.zeros((batchSize, numAnchors, grid_size, grid_size, 4)))\n",
        "\n",
        "    for batch_index, target in enumerate(targets):\n",
        "        x1, y1, x2, y2 = target.long()\n",
        "        x_center, y_center, width, height = (x1 + x2) / 2, (y1 + y2) / 2, x2 - x1, y2 - y1\n",
        "\n",
        "        for i, grid_size in enumerate(gridSizes):\n",
        "            x_cell, y_cell = int(x_center * grid_size), int(y_center * grid_size)\n",
        "            anchor = 0\n",
        "            try:\n",
        "                targetObj[i][batch_index, anchor, y_cell, x_cell, 0] = 1\n",
        "                targetBox[i][batch_index, anchor, y_cell, x_cell] = torch.tensor([x_center, y_center, width, height])\n",
        "            except Exception as e:\n",
        "                pass\n",
        "    return targetObj, targetBox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCXFHrH5zfQx"
      },
      "outputs": [],
      "source": [
        "\n",
        "class SignboardLoss(nn.Module):\n",
        "    def __init__(self, num_anchors=3):\n",
        "        super(SignboardLoss, self).__init__()\n",
        "        self.num_anchors = num_anchors\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        objectLoss = torch.tensor(0.0, device=preds[0].device)\n",
        "        boxLoss = torch.tensor(0.0, device=preds[0].device)\n",
        "        batchSize = preds[0].size(0)\n",
        "        gridSizes = [pred.size(2) for pred in preds]\n",
        "        targetObjList, targetBoxList = TargetstoTensors(targets, batchSize, self.num_anchors, gridSizes)\n",
        "\n",
        "        for i, pred in enumerate(preds):\n",
        "            targetObj = targetObjList[i].to(pred.device)\n",
        "            targetBox = targetBoxList[i].to(pred.device)\n",
        "\n",
        "            objectLoss += nn.BCEWithLogitsLoss()(pred[..., 4:5], targetObj)\n",
        "            boxLoss += nn.MSELoss()(pred[..., :4], targetBox)\n",
        "\n",
        "        total_loss = objectLoss + boxLoss\n",
        "        return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZJ8-pMgbu-9"
      },
      "outputs": [],
      "source": [
        "def CreateYolov5Model(numClasses: int, version: str):\n",
        "    congfigFile = \"yolov5/models/yolov5{}.yaml\".format(version)\n",
        "    model = Model(congfigFile, ch=3, nc=numClasses)\n",
        "    # model.load_state_dict(torch.load(\"yolov5{}.pt\".format(version))[\"model\"].state_dict(), strict=False)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def TrainEpoch(model, dataLoader, optimizer, lossFunction, device):\n",
        "    print(\"Training Epoch\")\n",
        "    model.train()\n",
        "    runningLoss = 0\n",
        "    dataLoaderLen = len(dataLoader)\n",
        "    for i, (inputs, targets) in enumerate(dataLoader):\n",
        "        inputs = inputs.permute(0, 3, 1, 2)\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with torch.set_grad_enabled(True):\n",
        "            outputs = model(inputs)\n",
        "            loss = lossFunction(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        runningLoss += loss.item() * inputs.size(0)\n",
        "        if(((i*100)//dataLoaderLen) % 10 == 0):\n",
        "            print((i*100//dataLoaderLen), end=\"%,\")\n",
        "    epochLoss = runningLoss / dataLoaderLen\n",
        "    return model, epochLoss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ValidateEpoch(model, dataLoader, lossFunction, device):\n",
        "    print(\"Validating Epoch\")\n",
        "    model.eval()\n",
        "    runningLoss = 0\n",
        "    dataLoaderLen = len(dataLoader)\n",
        "    for i, (inputs, targets) in enumerate(dataLoader):\n",
        "        inputs = inputs.permute(0, 3, 1, 2)\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        with torch.set_grad_enabled(False):\n",
        "            outputs = model(inputs)\n",
        "            loss = lossFunction(outputs, targets)\n",
        "        runningLoss += loss.item() * inputs.size(0)\n",
        "        if(((i*100)//dataLoaderLen) % 10 == 0):\n",
        "            print((i*100//dataLoaderLen), end=\"%,\")\n",
        "    epochLoss = runningLoss / dataLoaderLen\n",
        "    return epochLoss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbVy1m6T3nB6"
      },
      "outputs": [],
      "source": [
        "def TrainModel(model, trainDataLoader, valDataLoader, epochs, optimizer, scheduler, lossFunction, device):\n",
        "    for epoch in range(epochs):\n",
        "        startTime = time()\n",
        "        print(\"Epoch {}/{}:\".format(epoch+1, epochs))\n",
        "        startTime = time()\n",
        "        model, trainingEpochLoss = TrainEpoch(model, trainDataLoader, optimizer, lossFunction, device)\n",
        "        # validationEpochLoss = ValidateEpoch(model, valDataLoader, lossFunction, device)\n",
        "        # scheduler.step(validationEpochLoss)\n",
        "        scheduler.step(trainingEpochLoss)\n",
        "        endTime = time()\n",
        "        timeTaken = endTime - startTime\n",
        "        print()\n",
        "        print(\"Training Loss: {:.4f}\".format(trainingEpochLoss))\n",
        "        # print(\"validation Loss: {:.4f}\".format(validationEpochLoss))\n",
        "        print(\"Time taken: {}min, {}, secs\".format(timeTaken//60, int(timeTaken % 60)))\n",
        "    \n",
        "    print(\"Training complete.\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4adeyZX3nB6"
      },
      "outputs": [],
      "source": [
        "batchSize = 32\n",
        "inputShape = (640, 640)\n",
        "epochs = 100\n",
        "numAnchors = 3\n",
        "yolo5Version = 'm'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_imN2T83nB6",
        "outputId": "5abee8fb-3512-4773-dcf1-e85a92c30ad0"
      },
      "outputs": [],
      "source": [
        "print(\"Using {} device\".format(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Downloading Weights of yolo5 Verion \", yolo5Version)\n",
        "weightsURL = \"https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5{}.pt\".format(yolo5Version)\n",
        "!wget {weightsURL}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z884-9l6bu--"
      },
      "outputs": [],
      "source": [
        "images, annotations, numClasses = LoadDataSet(\"./DataSet\")\n",
        "numClasses = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJAmoLT33nB6"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = PreProcessDataSet(\n",
        "    images, annotations, batchSize, inputShape)\n",
        "del images\n",
        "del annotations\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IkU27xh3nB6"
      },
      "outputs": [],
      "source": [
        "trainDataLoader, valDataLoader = CreateDataLoaders(\n",
        "    X_train, X_val, y_train, y_val, batchSize)\n",
        "del X_train\n",
        "del y_train\n",
        "del X_val\n",
        "del y_val\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJrRAHOrbu--",
        "outputId": "3cd16fbb-87f6-4a41-8663-76ace9abf5f1"
      },
      "outputs": [],
      "source": [
        "yolov5Model = CreateYolov5Model(numClasses,yolo5Version)\n",
        "optimizer = optim.Adam(yolov5Model.parameters(), lr=0.001)\n",
        "yolov5LossFunction= SignboardLoss()\n",
        "yolov5Model = yolov5Model.to(device)\n",
        "yolov5LossFunction = yolov5LossFunction.to(device)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Atpoji13nB7",
        "outputId": "2b644c47-c751-4e4f-f561-5d9d6f549d94"
      },
      "outputs": [],
      "source": [
        "trainedModel = TrainModel(yolov5Model, trainDataLoader,valDataLoader, epochs, optimizer, scheduler, yolov5LossFunction, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGDk5r7d3nB7"
      },
      "outputs": [],
      "source": [
        "date = datetime.now()\n",
        "date = date.strftime(\"%m-%d-%H\")\n",
        "torch.save(trainedModel.state_dict(), 'yolov5Model' + date +'.pth')\n",
        "shutil.copy('/content/yolov5Model' + date +'.pth', '/content/drive/MyDrive/DL Project/Trained Models/yolov5Model' + date +'.pth')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
