{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResizeImage(image: np.ndarray, x1: int, y1: int, x2: int, y2: int, newWidth: int, newHeight: int) -> tuple:\n",
    "    originalHeight, originalWidth = image.shape[:2]\n",
    "    widthScale = newWidth / originalWidth\n",
    "    heightScale = newHeight / originalHeight\n",
    "    resizedImage = cv2.resize(\n",
    "        image, (newWidth, newHeight), interpolation=cv2.INTER_LINEAR)\n",
    "    x1New, y1New = int(x1 * widthScale), int(y1 * heightScale)\n",
    "    x2New, y2New = int(x2 * widthScale), int(y2 * heightScale)\n",
    "    return resizedImage, x1New, y1New, x2New, y2New\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertLisaToYolo(dataSetFolderPath: str ):\n",
    "    # annotations = []\n",
    "    annotationsFilePath = dataSetFolderPath+\"/annotations.csv\"\n",
    "    annotationsDataFrame = pd.read_csv(annotationsFilePath, sep=',')\n",
    "    uniqueSigns = annotationsDataFrame['class'].unique().tolist()\n",
    "    uniqueFiles = annotationsDataFrame['filename'].unique()\n",
    "    for file in uniqueFiles:\n",
    "        image_file = os.path.join(dataSetFolderPath, file)\n",
    "        if not os.path.exists(image_file):\n",
    "            continue\n",
    "        fileDataFrame = annotationsDataFrame[annotationsDataFrame['filename'] == file]\n",
    "        fileAnnotations = []\n",
    "        for index, row in fileDataFrame.iterrows():\n",
    "\n",
    "            image = cv2.imread(dataSetFolderPath+\"/\"+row[0])\n",
    "\n",
    "            resizedImage, x1, y1, x2, y2 = ResizeImage(image, row[1], row[2], row[3], row[4], 640, 640)\n",
    "            # x1, y1, x2, y2 = row[2], row[3], row[4], row[5]\n",
    "            h, w, _ = image.shape\n",
    "            xCenter = ((x1 + x2) // 2) / w\n",
    "            yCenter = ((y1 + y2) // 2) / h\n",
    "            width = (x2 - x1) / w\n",
    "            height = (y2 - y1) / h\n",
    "            classId = uniqueSigns.index(row[5])\n",
    "            cv2.imwrite(\"./newYoloV5DataSet\"+\"/\"+file.split(\"/\")[-1], resizedImage)\n",
    "            fileAnnotations.append(f\"{classId} {xCenter} {yCenter} {width} {height}\")\n",
    "        # filepath = \"./YoloV5DataSet/\"+\"/\".join(file.split(\"/\")[:-1])\n",
    "        # print(filepath)\n",
    "        with open(os.path.join('./newYoloV5DataSet', f\"{Path(file).stem}.txt\"), \"w\") as f:\n",
    "            f.write(\"\\n\".join(fileAnnotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateTrainValFiles(dataSetFolderPath: str):\n",
    "    annotationsFilePath = \"./DataSet2/annotations.csv\"\n",
    "    annotationsDataFrame = pd.read_csv(annotationsFilePath, sep=',')\n",
    "    uniqueSigns = annotationsDataFrame['class'].unique().tolist()\n",
    "    uniqueFiles = annotationsDataFrame['filename'].unique().tolist()\n",
    "    image_files = [dataSetFolderPath+\"/\"+f for f in os.listdir(dataSetFolderPath) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "\n",
    "    # image_files = [\"./DataSet/\" + file for file in uniqueFiles ]\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    split_ratio = 0.8\n",
    "    train_files = image_files[:int(len(image_files) * split_ratio)]\n",
    "    val_files = image_files[int(len(image_files) * split_ratio):]\n",
    "\n",
    "    with open(\"train.txt\", \"w\") as f:\n",
    "        f.writelines([ file + \"\\n\" for file in train_files])\n",
    "\n",
    "    with open(\"val.txt\", \"w\") as f:\n",
    "        f.writelines([file + \"\\n\" for file in val_files])\n",
    "    return len(uniqueSigns), uniqueSigns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def CreateYaml(fileName: str, numClass: int, classList: list):\n",
    "    data = {\n",
    "    'train': './train.txt',\n",
    "    'val': './val.txt',\n",
    "    'nc': numClass,\n",
    "    'names': classList\n",
    "    }\n",
    "\n",
    "    with open(fileName, 'w') as file:\n",
    "        yaml.dump(data, file, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('./newYoloV5DataSet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvertLisaToYolo('./DataSet2')\n",
    "numClass, classList = CreateTrainValFiles('./newYoloV5DataSet')\n",
    "CreateYaml('signboard.yaml', numClass, classList)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
