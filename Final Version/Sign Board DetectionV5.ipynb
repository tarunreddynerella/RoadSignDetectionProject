{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39900,"status":"ok","timestamp":1682789221506,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"NLuliN1UcKJ7","outputId":"59b3f7a4-1a3f-44bd-b045-ebce5644a0ad"},"outputs":[],"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    import zipfile\n","    with zipfile.ZipFile('/content/drive/MyDrive/DL Project/DataSet1.zip', 'r') as zip_ref:\n","        zip_ref.extractall('./DataSet1')\n","except:\n","    print(\"Using Local Machine\")\n","!git clone https://github.com/ultralytics/yolov5.git\n","!pip install -r yolov5/requirements.txt\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7188,"status":"ok","timestamp":1682789228691,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"nQdle6ECbu-5"},"outputs":[],"source":["# Include all packages\n","import gc\n","import cv2\n","import shutil\n","import random\n","import numpy as np\n","import pandas as pd\n","from time import time\n","from copy import deepcopy\n","\n","from datetime import datetime\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","from yolov5.models.yolo import Model\n","\n","from sklearn.cluster import KMeans\n","from sklearn.model_selection import train_test_split\n","\n","import torchvision\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682789228691,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"SxOLsWl2cKJ8"},"outputs":[],"source":["def CannyEdge(capturedImage):\n","    grayScale = cv2.cvtColor(capturedImage, cv2.COLOR_BGR2GRAY)\n","    gaussianImage = cv2.GaussianBlur(grayScale, (3, 3), 0)\n","    imageMedian = np.median(capturedImage)\n","    lowerThreshold = max(0, (0.7 * imageMedian))\n","    upperThreshold = min(255, (0.7 * imageMedian))\n","    cannyEdgeImage = cv2.Canny(gaussianImage, lowerThreshold, upperThreshold)\n","    cannyEdgeImage = cv2.bitwise_not(cannyEdgeImage)\n","    cannyEdgeImage = cv2.cvtColor(cannyEdgeImage, cv2.COLOR_GRAY2BGR)\n","    return cannyEdgeImage\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682789228691,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"Xd2tU8GB3nB3"},"outputs":[],"source":["def ResizeImage(image: np.ndarray, x1: int, y1: int, x2: int, y2: int, newWidth: int, newHeight: int) -> tuple:\n","    originalHeight, originalWidth = image.shape[:2]\n","    resizedImage = cv2.resize(\n","        image, (newWidth, newHeight), interpolation=cv2.INTER_LINEAR)\n","    widthScale = newWidth / originalWidth\n","    heightScale = newHeight / originalHeight\n","    x1New, y1New = int(x1 * widthScale), int(y1 * heightScale)\n","    x2New, y2New = int(x2 * widthScale), int(y2 * heightScale)\n","    return resizedImage, x1New, y1New, x2New, y2New\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1682789228691,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"9iMxCddibu-7"},"outputs":[],"source":["def LoadDataSet(dataSetFolderPath: str) -> tuple:\n","    images = []\n","    annotations = []\n","    resize = (640, 640)\n","    annotationsFilePath = dataSetFolderPath+\"/annotations.csv\"\n","    annotationsDataFrame = pd.read_csv(annotationsFilePath, sep=\",\")\n","    uniqueSigns = annotationsDataFrame['class'].unique().tolist()\n","    for index, row in annotationsDataFrame[1:].iterrows():\n","        image = cv2.imread(dataSetFolderPath+\"/\"+row[0])\n","        [classIndex, x1, y1, x2, y2] = [uniqueSigns.index(row[5]), row[1], row[2], row[3], row[4]]\n","        resizedImage, x1New, y1New, x2New, y2New = ResizeImage(image, x1, y1, x2, y2, resize[0], resize[1])\n","        # resizedImage = CannyEdge(resizedImage)\n","        images.append(resizedImage)\n","        annotations.append(\n","            [classIndex, x1New, y1New, x2New, y2New])\n","    del annotationsDataFrame\n","\n","    X_train, X_val, y_train, y_val = train_test_split(images, annotations, test_size=0.2, random_state=42)\n","\n","    return len(uniqueSigns), X_train, X_val, y_train, y_val, annotations\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1682789228691,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"68sCzcEAbu-7"},"outputs":[],"source":["class CustomDataset(Dataset):\n","\n","    def __init__(self, data, transform=None):\n","        self.data = data\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        inputData, label = self.data[idx]\n","\n","        if self.transform:\n","            inputData = self.transform(inputData)\n","        inputData = torch.from_numpy(inputData).float()\n","        label = torch.tensor(label).float()\n","        return inputData, label\n","\n","\n","def CreateDataLoaders(X_train, X_val, y_train, y_val, batchSize):\n","    trainDataSet = []\n","    valDataSet = []\n","    trainDataSet = list(zip(X_train, y_train))\n","    valDataSet = list(zip(X_val, y_val))\n","\n","    trainDataSet = CustomDataset(trainDataSet)\n","    valDataSet = CustomDataset(valDataSet)\n","    trainDataLoader = DataLoader(\n","        trainDataSet, batch_size=batchSize, shuffle=True, num_workers=4, pin_memory=True)\n","    valDataLoader = DataLoader(\n","        valDataSet, batch_size=batchSize, shuffle=False, num_workers=4, pin_memory=True)\n","\n","    return trainDataLoader, valDataLoader\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682789228692,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"owhzzQF61a0L"},"outputs":[],"source":["def GetAnchorValues(annotations, numAnchors):\n","    aspect_ratios = []\n","\n","    for annotation in annotations:\n","        x1, y1, x2, y2 = annotation\n","        width, height = x2 - x1, y2 - y1\n","        aspect_ratios.append([width, height])\n","\n","    aspect_ratios = np.array(aspect_ratios)\n","\n","    kmeans = KMeans(n_clusters=numAnchors, random_state=0)\n","    kmeans.fit(aspect_ratios)\n","\n","    anchorValues = kmeans.cluster_centers_\n","\n","    return anchorValues.tolist()\n","\n","\n","def calculateIOU(box1, box2):\n","    x1Center, y1Center, width1, height1 = box1\n","    x2Center, y2Center, width2, height2 = box2\n","\n","    x1, y1 = x1Center - width1 / 2, y1Center - height1 / 2\n","    x2, y2 = x2Center + width1 / 2, y1Center + height1 / 2\n","    x3, y3 = x2Center - width2 / 2, y2Center - height2 / 2\n","    x4, y4 = x2Center + width2 / 2, y2Center + height2 / 2\n","\n","    xIntersection = max(0, min(x2, x4) - max(x1, x3))\n","    yIntersection = max(0, min(y2, y4) - max(y1, y3))\n","\n","    intersectionArea = xIntersection * yIntersection\n","    box1Area = width1 * height1\n","    box2Area = width2 * height2\n","    unionArea = box1Area + box2Area - intersectionArea\n","\n","    iou = intersectionArea / unionArea\n","    return iou\n","\n","def TargetstoTensors(targets, batchSize, numAnchors, gridSizes, numClasses, anchors):\n","    targetObj = []\n","    targetBox = []\n","    targetClass = []\n","    for grid_size in gridSizes:\n","        targetObj.append(torch.zeros(\n","            (batchSize, numAnchors, grid_size, grid_size, 1)))\n","        targetBox.append(torch.zeros(\n","            (batchSize, numAnchors, grid_size, grid_size, 4)))\n","        targetClass.append(torch.zeros(\n","            (batchSize, numAnchors, grid_size, grid_size, numClasses)))\n","\n","    for batch_index, target in enumerate(targets):\n","        classindex, x1, y1, x2, y2 = target\n","        x_center, y_center, width, height = (\n","            x1 + x2) / 2, (y1 + y2) / 2, x2 - x1, y2 - y1\n","\n","        for i, grid_size in enumerate(gridSizes):\n","            x_cell, y_cell = int(\n","                x_center * grid_size), int(y_center * grid_size)\n","            anchor = 0\n","            ious = []\n","            for a in anchors[i]:\n","                iou = calculateIOU([x_center, y_center, width, height], a)\n","                ious.append(iou)\n","            anchor = torch.argmax(torch.tensor(ious))\n","            try:\n","                targetObj[i][batch_index, anchor, y_cell, x_cell, 0] = 1\n","                targetBox[i][batch_index, anchor, y_cell, x_cell] = torch.tensor(\n","                    [x_center, y_center, width, height])\n","                targetClass[i][batch_index, anchor,\n","                               y_cell, x_cell, classindex] = 1\n","            except Exception as e:\n","                pass\n","    return targetObj, targetBox, targetClass\n","\n","\n","class SignboardLoss(nn.Module):\n","    def __init__(self, numAnchors=3, anchorValues=[], numClasses=0):\n","        super(SignboardLoss, self).__init__()\n","        self.numAnchors = numAnchors\n","        self.numClasses = numClasses\n","        self.anchorValues = anchorValues\n","\n","    def forward(self, preds, targets):\n","        objectLoss = torch.tensor(0.0, device=preds[0].device)\n","        boxLoss = torch.tensor(0.0, device=preds[0].device)\n","        classLoss = torch.tensor(0.0, device=preds[0].device)\n","        batchSize = preds[0].size(0)\n","        gridSizes = [pred.size(2) for pred in preds]\n","        targetObjList, targetBoxList, targetClassList = TargetstoTensors(\n","            targets, batchSize, self.numAnchors, gridSizes, self.numClasses, self.anchorValues )\n","\n","        for i, pred in enumerate(preds):\n","            targetObj = targetObjList[i].to(pred.device)\n","            targetBox = targetBoxList[i].to(pred.device)\n","            targetClass = targetClassList[i].to(pred.device)\n","\n","            objectLoss += nn.BCEWithLogitsLoss()(pred[..., 4:5], targetObj)\n","            boxLoss += nn.MSELoss()(pred[..., :4], targetBox)\n","            classLoss += nn.BCEWithLogitsLoss()(pred[..., 5:], targetClass)\n","\n","        total_loss = objectLoss + boxLoss + classLoss\n","        return total_loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682789228692,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"AZJ8-pMgbu-9"},"outputs":[],"source":["def CreateYolov5Model(numClasses: int, version: str, device):\n","    congfigFile = \"yolov5/models/yolov5{}.yaml\".format(version)\n","    model = Model(congfigFile, ch=3, nc=numClasses)\n","    ckpt = torch.load(f'yolov5{version}.pt', map_location=device)\n","    ckpt_model_dict = ckpt['model'].state_dict()\n","    compatible_weights = {k: v for k, v in ckpt_model_dict.items(\n","    ) if k in model.state_dict() and model.state_dict()[k].shape == v.shape}\n","    model.load_state_dict(compatible_weights, strict=False)\n","    model.hyp = ckpt['model'].hyp\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682789228692,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"bWVv6VcgcKJ-"},"outputs":[],"source":["def TrainEpoch(model, dataLoader, optimizer, lossFunction, device):\n","    print(\"Training Epoch\")\n","    model.train()\n","    runningLoss = 0\n","    dataLoaderLen = len(dataLoader)\n","    for i, (inputs, targets) in enumerate(dataLoader):\n","        # inputs = inputs.permute(2, 0, 1)\n","        inputs = inputs.permute(0, 3, 1, 2)\n","        inputs = inputs.to(device)\n","        targets = targets.to(device)\n","        optimizer.zero_grad()\n","        with torch.set_grad_enabled(True):\n","            outputs = model(inputs)\n","            loss = lossFunction(outputs, targets)\n","            loss.backward()\n","            optimizer.step()\n","\n","        runningLoss += loss.item() * inputs.size(0)\n","        if(((i*100)//dataLoaderLen) % 10 == 0):\n","            print((i*100//dataLoaderLen), end=\"%,\")\n","    print()\n","    epochLoss = runningLoss / dataLoaderLen\n","    return model, epochLoss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682789228692,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"g3l_D4syBmlL"},"outputs":[],"source":["def ValidateEpoch(model, dataLoader, lossFunction, device):\n","    print(\"Validating Epoch\")\n","    model.eval()\n","    runningLoss = 0\n","    dataLoaderLen = len(dataLoader)\n","    for i, (inputs, targets) in enumerate(dataLoader):\n","        inputs = inputs.permute(0, 3, 1, 2)\n","        inputs = inputs.to(device)\n","        targets = targets.to(device)\n","        with torch.set_grad_enabled(False):\n","            outputs = model(inputs)\n","            loss = lossFunction(outputs, targets)\n","        runningLoss += loss.item() * inputs.size(0)\n","        if(((i*100)//dataLoaderLen) % 10 == 0):\n","            print((i*100//dataLoaderLen), end=\"%,\")\n","    print()\n","    epochLoss = runningLoss / dataLoaderLen\n","    return epochLoss\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1682789228692,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"GCtFNZeAcKJ-"},"outputs":[],"source":["def DetectImage(model, inputs, device, conf_thres=0.2, iou_thres=0.5):\n","    model.eval()\n","\n","    inputs = torch.tensor(inputs, dtype=torch.float32)\n","    inputs = inputs.unsqueeze(0)\n","    inputs = inputs.permute(0, 3, 1, 2)\n","    inputs = inputs.to(device)\n","    conf_thres = torch.tensor(conf_thres)\n","    with torch.no_grad():\n","        output = model(inputs)\n","        output = output[0]\n","        confidences = output[..., 4:5]\n","        max_confidences, max_indices = torch.max(confidences, dim=1)\n","        box_coordinates = output[..., :4].view(-1, 4)\n","        confidence_scores = output[..., 4].view(-1)\n","        nms_indices = torchvision.ops.nms(box_coordinates, confidence_scores, iou_thres)\n","        # output = output.view(-1, output.shape[-1])[nms_indices]\n","        output = output.view(-1, output.shape[-1])[max_indices]\n","    output = output.squeeze(0)\n","    return output\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1682789228692,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"Vmu96jtn_Xv5"},"outputs":[],"source":["\n","def EvaluateModel(yolov5Model, X_val: list, y_val: list, device ):\n","    randInt = random.randint(0,len(X_val))\n","    image = X_val[randInt]\n","    image1 = deepcopy(image)\n","    predictions = DetectImage(yolov5Model, image, device)\n","    [a1,b1,a2,b2] = y_val[randInt]\n","    bBoxs = []\n","    machingbBoxes = []\n","    albBoxs =[]\n","\n","    for pred in predictions:\n","        x1, y1, x2, y2, m1,m2 = pred[:6]\n","        m1,m2, x1, y1, x2, y2= int(m1), int(m2),int(x1), int(y1), int(x2), int(y2)\n","        if(a1 == x1 or a2 == x2 or b1 == y1 or b2 == y2 ):\n","            if(((x1-x2) >= 17 and (x1-x2) <= 32) and ((y1-y2) >= 31 and (y1-y2)<= 56) ):\n","                machingbBoxes.append([x1, y1, x2,y2])\n","        \n","        if(abs(x1-x2) >= 17  and abs(y1-y2) >= 31 ):\n","            albBoxs.append([x1, y1, x2, y2])\n","\n","        if((abs(x1-x2) >= 17 and abs(x1-x2) <= 32) and (abs(y1-y2) >= 31 and abs(y1-y2)<= 56) ):\n","            bBoxs.append([x1, y1, x2, y2])\n","        \n","        \n","        # x_center, y_center, width, height =x1, y1, x2, y2\n","        # x1 = x_center - (width // 2)\n","        # y1 = y_center - (height // 2)\n","        # x2 = x_center + (width // 2)\n","        # y2 = y_center + (height // 2)\n","\n","    print(\"No. machingbBoxes detected:\" ,len(machingbBoxes) )\n","    print(\"No. albBoxs detected:\" ,len(albBoxs) )\n","    print(\"No. bBoxs detected:\" ,len(bBoxs) )\n","\n","\n","\n","\n","    for bBox in machingbBoxes:\n","        [x1, y1, x2, y2] = bBox\n","        cv2.rectangle(image, (x1, y1), (x2, y2), (0,0,0), 2)\n","\n","    for bBox in albBoxs:\n","        [x1, y1, x2, y2] = bBox\n","        cv2.rectangle(image, (x1, y1), (x2, y2), (0,0,255), 2)\n","\n","    for bBox in bBoxs:\n","        [x1, y1, x2, y2] = bBox\n","        cv2.rectangle(image, (x1, y1), (x2, y2), (255,0,0), 2)\n","\n","    cv2.rectangle(image, (a1, b1), (a2, b2), (0,255,0), 2)\n","\n","\n","    try:\n","        from google.colab.patches import cv2_imshow\n","        cv2_imshow(image)\n","    except:\n","        print(\"using Local\")\n","        cv2.imshow(\"Input Image\", image)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682789228693,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"YbVy1m6T3nB6"},"outputs":[],"source":["def TrainModel(model, trainDataLoader, valDataLoader, epochs, optimizer, scheduler, lossFunction, device, early_stopping_patience= 10):\n","    best_val_loss = np.inf\n","    epochs_without_improvement = 0\n","    best_model = None\n","    for epoch in range(epochs):\n","        startTime = time()\n","        print(\"Epoch {}/{}:\".format(epoch+1, epochs))\n","        startTime = time()\n","        model, trainingEpochLoss = TrainEpoch(model, trainDataLoader, optimizer, lossFunction, device)\n","        validationEpochLoss = ValidateEpoch(model, valDataLoader, lossFunction, device)\n","        scheduler.step(validationEpochLoss)\n","        scheduler.step(trainingEpochLoss)\n","        endTime = time()\n","        timeTaken = endTime - startTime\n","        \n","        if validationEpochLoss < best_val_loss:\n","            best_val_loss = validationEpochLoss\n","            best_model = model.state_dict()\n","            torch.save(best_model, 'best_model.pt')\n","            epochs_without_improvement = 0\n","        else:\n","            epochs_without_improvement += 1\n","\n","        print(\"Training Loss: {:.4f}\".format(trainingEpochLoss))\n","        print(\"validation Loss: {:.4f}\".format(validationEpochLoss))\n","        print(\"Time taken: {}min, {}, secs\".format(timeTaken//60, int(timeTaken % 60)))\n","        if (epochs_without_improvement >= early_stopping_patience):\n","            print(\"Early stopping triggered. No improvement in validation loss for {} epochs.\".format(early_stopping_patience))\n","            break\n","    print(\"Training complete.\")\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1682789229546,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"n4adeyZX3nB6"},"outputs":[],"source":["batchSize = 32\n","inputShape = (640, 640)\n","epochs = 100\n","numAnchors = 3\n","yolo5Version = 's'\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1682789229546,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"A_imN2T83nB6","outputId":"04adf1cd-c96c-447f-a899-72b212b134a5"},"outputs":[],"source":["print(\"Using {} device\".format(device))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1430,"status":"ok","timestamp":1682789230971,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"h5e6cK8HcKJ_","outputId":"3329e4df-4a17-44f1-98b8-fe0075260444"},"outputs":[],"source":["print(\"Downloading Weights of yolo5 Verion \", yolo5Version)\n","weightsURL = \"https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5{}.pt\".format(\n","    yolo5Version)\n","!wget {weightsURL}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8452,"status":"ok","timestamp":1682789239422,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"Z884-9l6bu--","outputId":"328c3020-0f73-4bed-f834-d4fc058c079a"},"outputs":[],"source":["numClasses, X_train, X_val, y_train, y_val, annotations = LoadDataSet(\"./DataSet1\")\n","print(numClasses)\n","gc.collect()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["anchorValues = GetAnchorValues(annotations, numAnchors)\n","print(anchorValues)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1682789239422,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"F5Roj9e3BmlM"},"outputs":[],"source":["# try:\n","#     from google.colab.patches import cv2_imshow\n","#     cv2_imshow(X_train[10])\n","# except:\n","#     print(\"using Local\")\n","#     cv2.imshow(\"Input Image\", X_train[10])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1682789239423,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"t0Vr59qSBmlN"},"outputs":[],"source":["trainDataLoader, valDataLoader = CreateDataLoaders(\n","    X_train, X_val, y_train, y_val, batchSize)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6793,"status":"ok","timestamp":1682789246205,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"WJrRAHOrbu--","outputId":"f0c5a931-ea45-481e-de99-c04bd8c07aac"},"outputs":[],"source":["yolov5Model = CreateYolov5Model(numClasses, yolo5Version, device)\n","optimizer = optim.Adam(yolov5Model.parameters(), lr=0.01)\n","yolov5LossFunction= SignboardLoss(numAnchors, anchorValues, numClasses)\n","yolov5Model = yolov5Model.to(device)\n","yolov5LossFunction = yolov5LossFunction.to(device)\n","scheduler = ReduceLROnPlateau(\n","    optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":52200,"status":"error","timestamp":1682789545288,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"9Atpoji13nB7","outputId":"4213798b-b682-47c5-a7d9-a5e52f8ef32c"},"outputs":[],"source":["trainedModel = TrainModel(yolov5Model, trainDataLoader,valDataLoader, epochs, optimizer, scheduler, yolov5LossFunction, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1682789545289,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"rGDk5r7d3nB7"},"outputs":[],"source":["date = datetime.now()\n","date = date.strftime(\"%m-%d-%H\")\n","torch.save(trainedModel.state_dict(), 'yolov5Modelv4-' + date +'.pth')\n","shutil.copy('/content/yolov5Modelv4-' + date +'.pth', '/content/drive/MyDrive/DL Project/Trained Models/yolov5Modelv4-' + date +'.pth')\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
