{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeiO4i-HfrFm",
        "outputId": "cb8fda19-7d2b-4396-f9b0-9786e2ab0b77"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "!pip install -r yolov5/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YblDrBQwfrFm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "from time import time\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, models, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZH5Fwa2frFn",
        "outputId": "422793fb-14c9-4252-cfe3-ca4af52dbeac"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/DL Project/TrafficSign DataSet.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall('./')\n",
        "except:\n",
        "    print(\"Using Local Machine\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTeGqiikfrFn"
      },
      "outputs": [],
      "source": [
        "def ResizeImage(image: np.ndarray, newWidth: int, newHeight: int) -> tuple:\n",
        "    resizedImage = cv2.resize(\n",
        "        image, (newWidth, newHeight), interpolation=cv2.INTER_LINEAR)\n",
        "    return resizedImage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5U5MD4XfrFn"
      },
      "outputs": [],
      "source": [
        "def LoadDataSet(dataSetFolderPath: str) -> tuple:\n",
        "    images = []\n",
        "    annotations = []\n",
        "    annotationsFilePath = dataSetFolderPath+\"/tafficSignAnnotations.csv\"\n",
        "    annotationsDataFrame = pd.read_csv(annotationsFilePath, sep=\", \")\n",
        "    print(annotationsDataFrame.columns)\n",
        "    uniqueSigns = annotationsDataFrame['Catoregy'].unique().tolist()\n",
        "    for index, row in annotationsDataFrame[1:].iterrows():\n",
        "        # print(\".\"+row[1])\n",
        "        image = cv2.imread(\".\"+row[1])\n",
        "        # print(image.shape)\n",
        "        images.append(image)\n",
        "        annotations.append(uniqueSigns.index(row[0]))\n",
        "    del annotationsDataFrame\n",
        "    return images, annotations, len(uniqueSigns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJBqn_oofrFn"
      },
      "outputs": [],
      "source": [
        "def PreProcessDataSet(images: list, annotations: list, batchSize: int, resize: tuple) -> tuple:\n",
        "    resizedImages = []\n",
        "    newAnnotations = []\n",
        "    for i, image in enumerate(images):\n",
        "        label = annotations[i]\n",
        "        resizedImage = ResizeImage(\n",
        "            image, resize[0], resize[1])\n",
        "        resizedImages.append(resizedImage)\n",
        "        newAnnotations.append(label)\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        resizedImages, newAnnotations, test_size=0.3, random_state=42)\n",
        "\n",
        "    return X_train, X_val, y_train, y_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qv40eGg-frFo"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inputData, label = self.data[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            inputData = self.transform(inputData)\n",
        "        inputData = torch.from_numpy(inputData).float()\n",
        "        label = torch.tensor(label)\n",
        "        return inputData, label\n",
        "\n",
        "def CreateDataLoaders(X_train, X_val, y_train, y_val, batchSize):\n",
        "    trainDataSet = []\n",
        "    valDataSet = []\n",
        "    for i in range(len(X_train)):\n",
        "        trainDataSet.append((X_train[i], y_train[i]))\n",
        "\n",
        "    for i in range(len(X_val)):\n",
        "        valDataSet.append((X_val[i], y_val[i]))\n",
        "\n",
        "    trainDataSet = CustomDataset(trainDataSet)\n",
        "    valDataSet = CustomDataset(valDataSet)\n",
        "    trainDataLoader = DataLoader(\n",
        "        trainDataSet, batch_size=batchSize, shuffle=True, num_workers=4)\n",
        "    valDataLoader = DataLoader(\n",
        "        valDataSet, batch_size=batchSize, shuffle=False, num_workers=4)\n",
        "\n",
        "    return trainDataLoader, valDataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lz_aHfOMfrFo"
      },
      "outputs": [],
      "source": [
        "def TrainModel(model, dataLoader, epochs, optimizer, criterion, device):\n",
        "    for epoch in range(epochs):\n",
        "        print(\"Epoch {}/{}:\".format(epoch+1, epochs))\n",
        "        startTime = time()\n",
        "        runningLoss = 0\n",
        "        dataLoaderLen = len(dataLoader)\n",
        "        runningAccuracy = 0\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(dataLoader):\n",
        "            inputs = inputs.permute(0, 3, 1, 2)\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            runningLoss += loss.item() * inputs.size(0)\n",
        "            runningAccuracy += torch.sum(preds == labels.data)\n",
        "            if(((i*100)//dataLoaderLen) % 10 == 0):\n",
        "                print((i*100//dataLoaderLen), end=\"%,\")\n",
        "        endTime = time()\n",
        "        timeTaken = endTime-startTime\n",
        "        epochLoss = runningLoss / dataLoaderLen\n",
        "        epochAccuracy = runningAccuracy.double() / dataLoaderLen\n",
        "        print()\n",
        "        print(\"Training Loss: {:.4f}\".format(epochLoss))\n",
        "        print(\"Training Accuracy: {:.4f}\".format(epochAccuracy))\n",
        "        print(\"Time taken: {}min, {}, secs\".format(timeTaken//60, timeTaken % 60))\n",
        "\n",
        "\n",
        "    print('Training complete')\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umnBxRB9frFo"
      },
      "outputs": [],
      "source": [
        "batchSize = 32\n",
        "inputShape = (416, 416)\n",
        "epochs = 100\n",
        "numAnchors = 3\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5btagm_yfrFp",
        "outputId": "9d33edba-f4cc-42e1-b636-11ff9b59e5a6"
      },
      "outputs": [],
      "source": [
        "print(\"Using {} device\".format(device))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQczbHPyfrFp",
        "outputId": "814ae4d0-682b-44fb-8850-7753474b2a4e"
      },
      "outputs": [],
      "source": [
        "images, annotations, numClasses = LoadDataSet(\"./TrafficSign DataSet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhLjobVzfrFp"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = PreProcessDataSet(\n",
        "    images, annotations, batchSize, inputShape)\n",
        "del images\n",
        "del annotations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJLSG14ffrFp"
      },
      "outputs": [],
      "source": [
        "trainDataLoader, valDataLoader = CreateDataLoaders(\n",
        "    X_train, X_val, y_train, y_val, batchSize)\n",
        "del X_train\n",
        "del y_train\n",
        "del X_val\n",
        "del y_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CBibRUEfrFp"
      },
      "outputs": [],
      "source": [
        "model = models.resnet50(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, numClasses)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN_Lbl3wfrFp",
        "outputId": "269e593c-5fb1-44dd-af13-6b6e11a089d8"
      },
      "outputs": [],
      "source": [
        "trainedModel = TrainModel(model, trainDataLoader, epochs, optimizer, criterion, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c25EsRHmfrFp",
        "outputId": "614349f3-fbea-4630-bbdf-254a48dd7873"
      },
      "outputs": [],
      "source": [
        "date = datetime.now()\n",
        "date = date.strftime(\"%m-%d-%H\")\n",
        "torch.save(trainedModel.state_dict(), 'signPredictionModel' + date +'.pth' )\n",
        "shutil.copy('/content/signPredictionModel' + date +'.pth', '/content/drive/MyDrive/DL Project/Trained Models/signPredictionModel' + date +'.pth')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
