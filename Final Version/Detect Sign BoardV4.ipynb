{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4869,"status":"ok","timestamp":1682618757536,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"L3U3WSH_p4Qw","outputId":"dfd9b821-0ac8-4765-bd62-25201aac5664"},"outputs":[],"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    import zipfile\n","    with zipfile.ZipFile('/content/drive/MyDrive/DL Project/DataSet1.zip', 'r') as zip_ref:\n","        zip_ref.extractall('./DataSet1')\n","except:\n","    print(\"Using Local Machine\")\n","!git clone https: // github.com/ultralytics/yolov5.git\n","!pip install - r yolov5/requirements.txt\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1682618762160,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"YH9O9SKQMgYO"},"outputs":[],"source":["# Include all packages\n","import os\n","import gc\n","import cv2\n","import shutil\n","import random\n","import numpy as np\n","import pandas as pd\n","from time import time\n","from copy import deepcopy\n","\n","from datetime import datetime\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","from yolov5.models.yolo import Model\n","from sklearn.model_selection import train_test_split\n","\n","import torchvision\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1682618762161,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"-VC_coAuMgYO"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1682618762161,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"RIo8lRlaMgYP"},"outputs":[],"source":["def CannyEdge(capturedImage):\n","    grayScale = cv2.cvtColor(capturedImage, cv2.COLOR_BGR2GRAY)\n","    constrastKernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n","    topHat = cv2.morphologyEx(grayScale, cv2.MORPH_TOPHAT, constrastKernel)\n","    blackHat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, constrastKernel)\n","    grayScale = grayScale + topHat - blackHat\n","    gaussianImage = cv2.GaussianBlur(grayScale, (3, 3), 0)\n","    imageMedian = np.median(capturedImage)\n","    lowerThreshold = max(0, (0.7 * imageMedian))\n","    upperThreshold = min(255, (0.7 * imageMedian))\n","    cannyEdgeImage = cv2.Canny(gaussianImage, lowerThreshold, upperThreshold)\n","    cannyEdgeImage = cv2.bitwise_not(cannyEdgeImage)\n","    cannyEdgeImage = cv2.cvtColor(cannyEdgeImage, cv2.COLOR_GRAY2BGR)\n","    return cannyEdgeImage\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1682618762161,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"w_qSITrUMgYP"},"outputs":[],"source":["def ResizeImage(image: np.ndarray, x1: int, y1: int, x2: int, y2: int, newWidth: int, newHeight: int) -> tuple:\n","    originalHeight, originalWidth = image.shape[:2]\n","    resizedImage = cv2.resize(\n","        image, (newWidth, newHeight), interpolation=cv2.INTER_LINEAR)\n","    widthScale = newWidth / originalWidth\n","    heightScale = newHeight / originalHeight\n","    x1New, y1New = int(x1 * widthScale), int(y1 * heightScale)\n","    x2New, y2New = int(x2 * widthScale), int(y2 * heightScale)\n","    return resizedImage, x1New, y1New, x2New, y2New\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1682618762162,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"DzSrOjv7MgYP"},"outputs":[],"source":["def LoadDataSet(dataSetFolderPath: str) -> tuple:\n","    images = []\n","    annotations = []\n","    resize = (640, 640)\n","    annotationsFilePath = dataSetFolderPath+\"/annotations.csv\"\n","    annotationsDataFrame = pd.read_csv(annotationsFilePath, sep=\",\")\n","    uniqueSigns = annotationsDataFrame['class'].unique().tolist()\n","    for index, row in annotationsDataFrame[1:].iterrows():\n","        image = cv2.imread(dataSetFolderPath+\"/\"+row[0])\n","        [classIndex, x1, y1, x2, y2] = [uniqueSigns.index(row[5]), row[1], row[2], row[3], row[4]]\n","        resizedImage, x1New, y1New, x2New, y2New = ResizeImage(image, x1, y1, x2, y2, resize[0], resize[1])\n","        # resizedImage = CannyEdge(resizedImage)\n","        images.append(resizedImage)\n","        annotations.append(\n","            [classIndex, x1New, y1New, x2New, y2New])\n","    del annotationsDataFrame\n","\n","    X_train, X_val, y_train, y_val = train_test_split(images, annotations, test_size=0.2, random_state=42)\n","\n","    return len(uniqueSigns), X_train, X_val, y_train, y_val\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1682618762162,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"VYcGr92mMgYQ"},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, data, transform=None):\n","        self.data = data\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        inputData, label = self.data[idx]\n","\n","        if self.transform:\n","            inputData = self.transform(inputData)\n","        inputData = torch.from_numpy(inputData).float()\n","        label = torch.tensor(label).float()\n","        return inputData, label\n","\n","\n","def CreateDataLoaders(X_train, X_val, y_train, y_val, batchSize):\n","    trainDataSet = []\n","    valDataSet = []\n","    for i in range(len(X_train)):\n","        trainDataSet.append((X_train[i], y_train[i]))\n","\n","    for i in range(len(X_val)):\n","        valDataSet.append((X_val[i], y_val[i]))\n","\n","    trainDataSet = CustomDataset(trainDataSet)\n","    valDataSet = CustomDataset(valDataSet)\n","    trainDataLoader = DataLoader(\n","        trainDataSet, batch_size=batchSize, shuffle=True, num_workers=4)\n","    valDataLoader = DataLoader(\n","        valDataSet, batch_size=batchSize, shuffle=False, num_workers=4)\n","\n","    return trainDataLoader, valDataLoader\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1682618762162,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"xhQjQ-UQMgYQ"},"outputs":[],"source":["def CreateYolov5Model(numClasses: int, version: str, device):\n","    congfigFile = \"yolov5/models/yolov5{}.yaml\".format(version)\n","    model = Model(congfigFile, ch=3, nc=numClasses)\n","    return model\n","\n","def LoadModel(yolov5Model):\n","    savedModels = [ modelName for modelName in os.listdir('/content/drive/MyDrive/DL Project/Trained Models/') if ('yolov5Modelv2' in modelName)]\n","    savedModels.sort()\n","    print(savedModels[-1])\n","    yolov5Model.load_state_dict(torch.load('/content/drive/MyDrive/DL Project/Trained Models/'+savedModels[-1], map_location=torch.device(device)))\n","    return yolov5Model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1682618762163,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"rkm--g-BMgYR"},"outputs":[],"source":["def DetectImage(model, inputs, device, conf_thres=0.2, iou_thres=0.5):\n","    model.eval()\n","\n","    inputs = torch.tensor(inputs, dtype=torch.float32)\n","    inputs = inputs.unsqueeze(0)\n","    inputs = inputs.permute(0, 3, 1, 2)\n","    inputs = inputs.to(device)\n","    conf_thres = torch.tensor(conf_thres)\n","    with torch.no_grad():\n","        output = model(inputs)\n","        output = output[0]\n","        confidences = output[..., 4:5]\n","        max_confidences, max_indices = torch.max(confidences, dim=1)\n","        box_coordinates = output[..., :4].view(-1, 4)\n","        confidence_scores = output[..., 4].view(-1)\n","        nms_indices = torchvision.ops.nms(box_coordinates, confidence_scores, iou_thres)\n","        # output = output.view(-1, output.shape[-1])[nms_indices]\n","        output = output.view(-1, output.shape[-1])[max_indices]\n","    output = output.squeeze(0)\n","    return output\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1682618762163,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"MbrCcAaEMgYR"},"outputs":[],"source":["batchSize = 32\n","inputShape = (640, 640)\n","epochs = 300\n","numAnchors = 3\n","yolo5Version = 'm'\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1682618762163,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"Yo5o2tQ0MgYR"},"outputs":[],"source":["print(\"Using {} device\".format(device))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8825,"status":"ok","timestamp":1682618770976,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"gDKfTcenMgYR"},"outputs":[],"source":["numClasses, X_train, X_val, y_train, y_val = LoadDataSet(\"./DataSet1\")\n","print(numClasses)\n","gc.collect()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# try:\n","#     from google.colab.patches import cv2_imshow\n","#     cv2_imshow(X_train[10])\n","# except:\n","#     print(\"using Local\")\n","#     cv2.imshow(\"Input Image\", X_train[10])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":613,"status":"ok","timestamp":1682618773334,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"-1xrW3kmMgYS","outputId":"23c71595-1939-4c9b-a150-50819ad51a00"},"outputs":[],"source":["yolov5Model = CreateYolov5Model(numClasses, yolo5Version, device)\n","yolov5Model = LoadModel(yolov5Model)\n","yolov5Model = yolov5Model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":711},"executionInfo":{"elapsed":3637,"status":"ok","timestamp":1682618789432,"user":{"displayName":"anudeep kalitar","userId":"01854914863512508282"},"user_tz":360},"id":"aMoAlEgdMgYS","outputId":"556244b2-1e55-4c6b-ec10-ed58ec6e36e8"},"outputs":[],"source":["randInt = random.randint(0,len(X_val))\n","image = X_val[randInt]\n","image1 = deepcopy(image)\n","predictions = DetectImage(yolov5Model, image, device)\n","[a1,b1,a2,b2] = y_val[randInt]\n","bBoxs = []\n","machingbBoxes = []\n","albBoxs =[]\n","\n","for pred in predictions:\n","    x1, y1, x2, y2, m1,m2 = pred[:6]\n","    m1,m2, x1, y1, x2, y2= int(m1), int(m2),int(x1), int(y1), int(x2), int(y2)\n","    if(a1 == x1 or a2 == x2 or b1 == y1 or b2 == y2 ):\n","      if(((x1-x2) >= 17 and (x1-x2) <= 32) and ((y1-y2) >= 31 and (y1-y2)<= 56) ):\n","        machingbBoxes.append([x1, y1, x2,y2])\n","      \n","    if(abs(x1-x2) >= 17  and abs(y1-y2) >= 31 ):\n","        albBoxs.append([x1, y1, x2, y2])\n","\n","    if((abs(x1-x2) >= 17 and abs(x1-x2) <= 32) and (abs(y1-y2) >= 31 and abs(y1-y2)<= 56) ):\n","        bBoxs.append([x1, y1, x2, y2])\n","    \n","    \n","    # x_center, y_center, width, height =x1, y1, x2, y2\n","    # x1 = x_center - (width // 2)\n","    # y1 = y_center - (height // 2)\n","    # x2 = x_center + (width // 2)\n","    # y2 = y_center + (height // 2)\n","\n","print(\"No. machingbBoxes detected:\" ,len(machingbBoxes) )\n","print(\"No. albBoxs detected:\" ,len(albBoxs) )\n","print(\"No. bBoxs detected:\" ,len(bBoxs) )\n","\n","\n","\n","\n","for bBox in machingbBoxes:\n","    [x1, y1, x2, y2] = bBox\n","    cv2.rectangle(image, (x1, y1), (x2, y2), (0,0,0), 2)\n","\n","for bBox in albBoxs:\n","    [x1, y1, x2, y2] = bBox\n","    cv2.rectangle(image, (x1, y1), (x2, y2), (0,0,255), 2)\n","\n","for bBox in bBoxs:\n","    [x1, y1, x2, y2] = bBox\n","    cv2.rectangle(image, (x1, y1), (x2, y2), (255,0,0), 2)\n","\n","cv2.rectangle(image, (a1, b1), (a2, b2), (0,255,0), 2)\n","\n","\n","try:\n","    from google.colab.patches import cv2_imshow\n","    cv2_imshow(image)\n","except:\n","    print(\"using Local\")\n","    cv2.imshow(\"Input Image\", image)\n","\n","\n","\n"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.0"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
